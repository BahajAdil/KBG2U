{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b1979381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from os.path import join\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from pathlib import Path\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from itertools import chain, groupby\n",
    "from typing import Any, List, Optional, Union\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, ComplementNB\n",
    "import joblib\n",
    "import numpy as np\n",
    "import torch\n",
    "from sentence_transformers import InputExample, SentenceTransformer, losses\n",
    "from sentence_transformers.losses import BatchHardTripletLossDistanceFunction as LossDistances\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from torch.utils.data import DataLoader\n",
    "import lightgbm as lgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "import json\n",
    "from glob import glob\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "StrOrPath = Union[Path, str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e6af32b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params():\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b93ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5dd61be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0+cu111'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "28eadd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "FACTUALITY_INT = {'Uncommitted':1, 'Fact':2,\n",
    "                  'Probable':3, 'Possible':4, 'Counterfact':5,\n",
    "                  'Doubtful':6, 'Conditional':7}\n",
    "FACTUALITY_INT_REV = {FACTUALITY_INT[i]:i for i in FACTUALITY_INT}\n",
    "MARGIN_LOSSES = ['', '']\n",
    "DISTANCE_LOSSES = ['BatchHardSoftMarginTripletLoss']\n",
    "MARG_DIST_LOSSES = ['BatchAllTripletLoss', 'BatchHardTripletLoss',\n",
    "                    'BatchSemiHardTripletLoss', 'ContrastiveLoss', 'TripletLoss']\n",
    "random_state = 1234\n",
    "FACT_DIR = '/home/pc/Desktop/AdilStuff/Projects/SemRepMed/semmed_data/FactualityData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e992da98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb0f18283b0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "torch.manual_seed(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d35499",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "62cdffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json_lines(file_name,dict_data):\n",
    "    json_string = json.dumps(dict_data)\n",
    "    with open(file_name, 'a') as f:\n",
    "        f.write(json_string+\"\\n\")\n",
    "        \n",
    "def read_json_lines(file_name):\n",
    "    lines = []\n",
    "    with open(file_name) as file_in:\n",
    "        for line in file_in:\n",
    "            lines.append(json.loads(line))\n",
    "    return lines\n",
    "def infer_fact(in_file_name, out_file_name):\n",
    "    args = Params()\n",
    "    # paraphrase-multilingual-mpnet-base-v2 paraphrase-albert-small-v2 all-mpnet-base-v2 all-MiniLM-L6-v2 \n",
    "    # all-MiniLM-L12-v2 \n",
    "    args.model_path = join(FACT_DIR, 'MODELS')\n",
    "    pip = FullPipe(args,\n",
    "        x_train= None,\n",
    "        y_train= None,\n",
    "        x_test= None,\n",
    "        y_test= None, mode = 'inference')\n",
    "    \n",
    "    with open(in_file_name) as file_in:\n",
    "        pbar = tqdm(total = 375866742)\n",
    "        for line in file_in:\n",
    "            lines = []\n",
    "            data = json.loads(line)\n",
    "            PREDICATION_AUX_ID = data['PREDICATION_AUX_ID']\n",
    "            SENTENCE, FORMATED_SENTENCE = data['SENTENCE'], data['FORMATED_SENTENCE']\n",
    "            label = pip.predict([FORMATED_SENTENCE])\n",
    "            label = label[1][0]\n",
    "            res_data = {}\n",
    "            res_data['PREDICATION_AUX_ID'], res_data['LABEL'] = PREDICATION_AUX_ID, label\n",
    "            write_json_lines(file_name = out_file_name, dict_data = res_data)\n",
    "            pbar.update()\n",
    "    return res_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fdd779",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1172cbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentTrans():\n",
    "    def __init__(self, args, x_train, y_train, x_test, y_test):\n",
    "        self.args = args\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        if hasattr(args, 'train_iter'):\n",
    "            self.train_iter = args.train_iter\n",
    "        if hasattr(args, 'warmup_steps'):\n",
    "            self.warmup_steps = args.warmup_steps\n",
    "        if hasattr(args, 'data_iter'):\n",
    "            self.data_iter = args.data_iter\n",
    "        if hasattr(args, 'n_neg'):\n",
    "            self.n_neg = args.n_neg\n",
    "        if hasattr(args, 'loss_margin'):\n",
    "            self.loss_margin = args.loss_margin\n",
    "        if hasattr(args, 'loss_name'):\n",
    "            self.loss_name = args.loss_name\n",
    "            loss =  get_loss(args.loss_name, args)\n",
    "        else:\n",
    "            self.loss_name = None\n",
    "            loss = None\n",
    "        if hasattr(args, 'loss_distance'):\n",
    "            self.loss_distance = get_distance(args.loss_distance)\n",
    "        if hasattr(args, 'model'):\n",
    "            self.model = SentenceTransformer(args.model)\n",
    "            self.model = self.model.to(device)\n",
    "        elif hasattr(args, 'model_path'):\n",
    "            self.model = SentenceTransformer(args.model_path)\n",
    "            self.model = self.model.to(device)\n",
    "        if loss is not None:\n",
    "            if self.loss_name in MARG_DIST_LOSSES:\n",
    "                self.loss = loss(self.model, self.loss_distance, self.loss_margin)\n",
    "            elif self.loss_name in DISTANCE_LOSSES:\n",
    "                self.loss = loss(self.model, self.loss_distance)\n",
    "            else:\n",
    "                self.loss = loss(self.model)\n",
    "        if self.loss_name is not None:\n",
    "            if 'Triplet' in self.loss_name:\n",
    "    #             train_examples = weighted_generate_multiple_sentence_triples(x_train, y_train, self.data_iter)\n",
    "                train_examples = mult_neg_weighted_generate_multiple_sentence_triples(x_train, y_train, self.n_neg, self.data_iter)\n",
    "            else:\n",
    "    #             train_examples = weighted_generate_multiple_sentence_pairs(self.x_train, self.y_train, self.data_iter)\n",
    "                train_examples = mult_neg_weighted_generate_multiple_sentence_pairs(self.x_train, self.y_train, self.n_neg,self.data_iter)\n",
    "    #         train_examples = generate_multiple_sentence_pairs(self.x_train, self.y_train, self.data_iter)\n",
    "    #         train_examples = generate_multiple_sentence_triples(x_train, y_train, self.data_iter)\n",
    "\n",
    "            self.train_dataloader = DataLoader(\n",
    "                    train_examples,\n",
    "                    shuffle=True,\n",
    "                    batch_size=args.batch_size,\n",
    "                    generator=torch.Generator(device='cpu'),\n",
    "            )\n",
    "\n",
    "#         self.loss = loss(self.model)\n",
    "        if self.x_train is not None:\n",
    "            self.X_train_noFT = self.model.encode(self.x_train)\n",
    "        if self.x_test is not None:\n",
    "            self.X_test_noFT = self.model.encode(self.x_test)\n",
    "        \n",
    "    def fit(self, show_progress_bar=True):\n",
    "        self.model.fit(\n",
    "            train_objectives=[(self.train_dataloader, self.loss)],\n",
    "            epochs=self.train_iter,\n",
    "            warmup_steps=self.warmup_steps,\n",
    "            show_progress_bar=show_progress_bar,\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def get_train_test_features(self):\n",
    "        return self.model.encode(self.x_train), self.model.encode(self.x_test)\n",
    "    \n",
    "    def get_embeddings(self, x):\n",
    "        return self.model.encode(x)\n",
    "    \n",
    "    def plot_(self):\n",
    "        plt.figure(figsize=(20,10))\n",
    "\n",
    "        #Plot X_train_noFit\n",
    "        X_embedded = TSNE(init='pca', n_components=2).fit_transform(np.array(self.X_train_noFT))\n",
    "        plt.subplot(221)\n",
    "        plt.title('X_train No Fit')\n",
    "\n",
    "        for i, t in enumerate(set(np.array(self.y_train))):\n",
    "            idx = np.array(self.y_train) == t\n",
    "            plt.scatter(X_embedded[idx, 0], X_embedded[idx, 1], label=FACTUALITY_INT_REV[t])   \n",
    "\n",
    "        plt.legend(bbox_to_anchor=(1, 1));\n",
    "\n",
    "        #Plot X_eval noFit\n",
    "        X_embedded = TSNE(init='pca',n_components=2).fit_transform(np.array(self.X_test_noFT))\n",
    "        plt.subplot(223)\n",
    "        plt.title('X_test No Fit')\n",
    "\n",
    "        for i, t in enumerate(set(np.array(self.y_test))):\n",
    "            idx = np.array(self.y_test) == t\n",
    "            plt.scatter(X_embedded[idx, 0], X_embedded[idx, 1], label=FACTUALITY_INT_REV[t])   \n",
    "\n",
    "        plt.legend(bbox_to_anchor=(1, 1));\n",
    "\n",
    "        X_train, X_test = self.get_train_test_features()\n",
    "        #Plot X_train SetFit\n",
    "        X_embedded = TSNE(init='pca',n_components=2).fit_transform(np.array(X_train))\n",
    "\n",
    "        plt.subplot(222)\n",
    "        plt.title('X_train SetFit')\n",
    "\n",
    "        for i, t in enumerate(set(np.array(self.y_train))):\n",
    "            idx = np.array(self.y_train) == t\n",
    "            plt.scatter(X_embedded[idx, 0], X_embedded[idx, 1], label=FACTUALITY_INT_REV[t])   \n",
    "\n",
    "        plt.legend(bbox_to_anchor=(1, 1));\n",
    "\n",
    "        #Plot X_eval SetFit\n",
    "        X_embedded = TSNE(init='pca',n_components=2).fit_transform(np.array(X_test))\n",
    "        plt.subplot(224)\n",
    "        plt.title('X_test SetFit')\n",
    "\n",
    "        for i, t in enumerate(set(np.array(self.y_test))):\n",
    "            idx = np.array(self.y_test) == t\n",
    "            plt.scatter(X_embedded[idx, 0], X_embedded[idx, 1], label=FACTUALITY_INT_REV[t])   \n",
    "\n",
    "        plt.legend(bbox_to_anchor=(1, 1))\n",
    "        plt.savefig('embedding_distribution.pdf', bbox_inches = 'tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a310124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead():\n",
    "    def __init__(self, args, x_train, y_train, x_test, y_test):\n",
    "        self.args = args\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.classifier = args.classifier\n",
    "        self.transformation = args.transformation\n",
    "        self.classifier = get_classifier_head(ch_name = self.classifier)\n",
    "        self.class_fitted = False\n",
    "        \n",
    "    def transform(self, x):\n",
    "        if self.transformation == 'normalize':\n",
    "            return preprocessing.normalize(x, norm='l2')\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    def fit(self):\n",
    "        self.classifier.fit(self.x_train, self.y_train)\n",
    "        self.class_fitted = True\n",
    "        \n",
    "    def fit_transform(self):\n",
    "        self.x_train = self.transform(self.x_train)\n",
    "        self.x_test = self.transform(self.x_test)\n",
    "        self.fit()\n",
    "        \n",
    "    def predict(self, x):\n",
    "        preds = self.classifier.predict(x)\n",
    "        return preds\n",
    "    \n",
    "    def report_test(self, output_dict = False):\n",
    "        if self.class_fitted:\n",
    "            test_peds = self.predict(self.x_test)\n",
    "            report = classification_report(self.y_test, test_peds,\n",
    "                                            labels = list(FACTUALITY_INT.values()),\n",
    "                                            output_dict=output_dict,\n",
    "                                            target_names=list(FACTUALITY_INT.keys()),\n",
    "                                            zero_division = True)\n",
    "            print(report)\n",
    "    def confusion_matrix(self):\n",
    "        if self.class_fitted:\n",
    "            predictions = self.predict(self.x_test)\n",
    "#             cm = confusion_matrix(self.y_test, predictions, display_labels=list(FACTUALITY_INT.values()),\n",
    "#                                   normalize='true')\n",
    "#             disp = ConfusionMatrixDisplay.from_predictions(confusion_matrix=cm,\n",
    "#                                           display_labels=list(FACTUALITY_INT.keys()))\n",
    "            disp = ConfusionMatrixDisplay.from_predictions(\n",
    "                self.y_test, predictions,labels = list(FACTUALITY_INT.values()),\n",
    "                display_labels=list(FACTUALITY_INT.keys()), xticks_rotation = 45, normalize= 'true'\n",
    "            )\n",
    "#             disp.plot()\n",
    "            plt.savefig('confusion_matrix.pdf', bbox_inches = 'tight')\n",
    "            plt.show()\n",
    "#             skplt.metrics.plot_confusion_matrix(self.y_test, predictions, x_tick_rotation=45,\n",
    "#                                                 labels=list(FACTUALITY_INT.keys()), normalize=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f98a5261",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullPipe():\n",
    "    def __init__(self, args, x_train, y_train, x_test, y_test, mode='train'):\n",
    "        random.seed(random_state)\n",
    "        np.random.seed(random_state)\n",
    "        torch.manual_seed(random_state)\n",
    "        if mode == 'train':\n",
    "            self.strans = SentTrans(args, x_train, y_train, x_test, y_test)\n",
    "            self.args = args\n",
    "            self.strans_fitted = False\n",
    "            self.class_model_fitted = False\n",
    "        elif mode == 'inference':\n",
    "            self.strans = SentTrans(args, None, None, None, None)\n",
    "            self.class_model = joblib.load(Path(args.model_path) / \"classifier.pkl\")\n",
    "            self.strans_fitted = True\n",
    "            self.class_model_fitted = True\n",
    "            \n",
    "    def fit(self):\n",
    "        self.strans.fit()\n",
    "        self.strans_fitted = True\n",
    "        x_train, x_test = self.strans.get_train_test_features()\n",
    "        y_train, y_test = self.strans.y_train, self.strans.y_test\n",
    "        self.class_model = ClassificationHead(self.args, x_train, y_train, x_test, y_test)\n",
    "        self.class_model.fit()\n",
    "        self.class_model_fitted = True\n",
    "        \n",
    "    def predict(self, x, y = None):\n",
    "        if self.strans_fitted & self.class_model_fitted:\n",
    "            x = self.strans.model.encode(x)\n",
    "            if len(x.shape) == 1:\n",
    "                x = x.reshape(1, -1)\n",
    "#             print(x.shape)\n",
    "#             print(type(x))\n",
    "            preds = self.class_model.predict(x)\n",
    "            return preds, [FACTUALITY_INT_REV[i] for i in list(preds)], y\n",
    "        else:\n",
    "            print('The models should be fitted')\n",
    "    \n",
    "    def evaluate(self):\n",
    "        self.strans.plot_()\n",
    "        self.class_model.report_test()\n",
    "        self.class_model.confusion_matrix()\n",
    "        \n",
    "    def save(\n",
    "        self,\n",
    "        path: StrOrPath,\n",
    "        model_name: Optional[str] = None,\n",
    "        create_model_card: bool = False,\n",
    "    ):\n",
    "        if (not self.class_model_fitted) and (not self.strans_fitted):\n",
    "            raise NotFittedError(\n",
    "                \"This SetFitClassifier instance is not fitted yet.\"\n",
    "                \" Call 'fit' with appropriate arguments before saving this estimator.\"\n",
    "            )\n",
    "        self.strans.model.save(str(path), self.args.model, create_model_card)\n",
    "        joblib.dump(self.class_model.classifier, Path(path) / \"classifier.pkl\")\n",
    "\n",
    "    def load(self, cls, path: StrOrPath):\n",
    "        args.model = path\n",
    "        self.strans = SentTrans(args, None, None, None, None)\n",
    "        self.class_model = joblib.load(Path(path) / \"classifier.pkl\")\n",
    "        return setfit\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c75decd",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9c891d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4ef1f8c86e435ca699f96f13392af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375866742 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43minfer_fact\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_file_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall_sentences.jsonl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_file_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall_sentences_facts.jsonl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [51]\u001b[0m, in \u001b[0;36minfer_fact\u001b[0;34m(in_file_name, out_file_name)\u001b[0m\n\u001b[1;32m     32\u001b[0m         res_data \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     33\u001b[0m         res_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPREDICATION_AUX_ID\u001b[39m\u001b[38;5;124m'\u001b[39m], res_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLABEL\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PREDICATION_AUX_ID, label\n\u001b[0;32m---> 34\u001b[0m         \u001b[43mwrite_json_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mout_file_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mres_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m         pbar\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_data\n",
      "Input \u001b[0;32mIn [51]\u001b[0m, in \u001b[0;36mwrite_json_lines\u001b[0;34m(file_name, dict_data)\u001b[0m\n\u001b[1;32m      2\u001b[0m json_string \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(dict_data)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 4\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(json_string\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "infer_fact(in_file_name = 'all_sentences.jsonl', out_file_name = 'all_sentences_facts.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab15c943",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42d186e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Params()\n",
    "# paraphrase-multilingual-mpnet-base-v2 paraphrase-albert-small-v2 all-mpnet-base-v2 all-MiniLM-L6-v2 \n",
    "# all-MiniLM-L12-v2 \n",
    "args.model_path = join(FACT_DIR, 'MODELS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e84831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip = FullPipe(args,\n",
    "        x_train= None,\n",
    "        y_train= None,\n",
    "        x_test= None,\n",
    "        y_test= None, mode = 'inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "415baa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = pip.predict(['Therapy       including aspirin, lipid agents (for example, statins),  @SUBJECT$ , beta-adrenergic blockers, postmenopausal estrogen replacement,       and vitamin E should be considered  @PREDICAT$   @OBJECT$  with type 2 diabetes.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cef02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = pip.predict([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "edee6a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Uncommitted'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = pip.predict([])\n",
    "cc[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f4431c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCE, FORMATED_SENTENCE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
